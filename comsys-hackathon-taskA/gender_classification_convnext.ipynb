{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id 1nzC-FjL5NtoUu-G2pkj9M8r7E79thK4R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /kaggle/working/Comys_Hackathon5.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **APPROACH :UNDERSAMPLING MAJORITY(MALE CLASS) ;EMBEDDER :ConvNext**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import timm \n",
    "\n",
    "#Seeding made fixed\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "# Dataset class with undersampling done\n",
    "class FaceGenderDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, undersample=False):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "\n",
    "        male_paths = []\n",
    "        female_paths = []\n",
    "\n",
    "        for gender_str in ['male', 'female']:\n",
    "            label = 0 if gender_str == 'male' else 1\n",
    "            folder = os.path.join(root_dir, gender_str)\n",
    "            for fname in os.listdir(folder):\n",
    "                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    path = os.path.join(folder, fname)\n",
    "                    if label == 0:\n",
    "                        male_paths.append((path, label))\n",
    "                    else:\n",
    "                        female_paths.append((path, label))\n",
    "\n",
    "        if undersample:\n",
    "            min_count = min(len(male_paths), len(female_paths))\n",
    "            male_paths = random.sample(male_paths, min_count)\n",
    "            female_paths = random.sample(female_paths, min_count)\n",
    "\n",
    "        self.samples = male_paths + female_paths\n",
    "        random.shuffle(self.samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label).float()\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.3, 0.3, 0.3),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#setting random seed for reproducibility\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "\n",
    "# Train and val loaders\n",
    "train_dataset = FaceGenderDataset(\"/kaggle/working/Comys_Hackathon5/Task_A/train\", transform=train_transform, undersample=True)\n",
    "val_dataset = FaceGenderDataset(\"/kaggle/working/Comys_Hackathon5/Task_A/train\", transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, generator=g, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Cuda initialisation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Focal Loss with Label Smoothing ===\n",
    "class FocalLossWithSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing=0.1, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        targets = targets * (1 - self.smoothing) + 0.5 * self.smoothing\n",
    "        bce = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "        pt = torch.exp(-bce)\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma * bce)\n",
    "        return focal_loss.mean()\n",
    "\n",
    "# ConvNext_Atto Model\n",
    "class ConvNeXtGenderClassifier(nn.Module):\n",
    "    def __init__(self, backbone='convnext_atto'):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(backbone, pretrained=True, num_classes=0)\n",
    "        self.classifier = nn.Linear(self.backbone.num_features, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features).squeeze(1)\n",
    "\n",
    "model = ConvNeXtGenderClassifier().to(device)\n",
    "\n",
    "# === Loss, Optimizer, Scheduler, Scaler ===\n",
    "criterion = FocalLossWithSmoothing(smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "scaler = GradScaler()\n",
    "\n",
    "#Setting up training\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "epochs = \n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" Training ConvNeXt with Undersampling \" + \"=\"*20 + \"\\n\")\n",
    "\n",
    "#Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).long()\n",
    "        correct += (preds == labels.long()).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    #Val loop\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct, val_total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).long()\n",
    "            val_correct += (preds == labels.long()).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_loss = val_running_loss / val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "   #Showing the output\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"✅ Best model updated (val_acc: {best_val_acc:.4f})\")\n",
    "\n",
    "#Saving the best model and it's weights\n",
    "if best_model_state is not None:\n",
    "    torch.save(best_model_state, \"best_convnext_gender_model.pth\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"✅ Best model saved as 'best_convnext_gender_model.pth'\")\n",
    "    print(f\"Final Best Validation Accuracy: {best_val_acc:.2%}\")\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(\"⚠️ No best model state was saved!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
