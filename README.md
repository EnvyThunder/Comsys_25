# ğŸ§  COMSYS 5 Hackathon

## ğŸ“ Repository Structure

```
â”œâ”€â”€ comsys-hackathon-taskA/
â”‚   â”œâ”€â”€ test_data/                       # hold-out test images
â”‚   â”œâ”€â”€ weights/
â”‚   â”‚   â””â”€â”€ best_convnext_gender_model.pth
â”‚   â”œâ”€â”€ download_data.py                 # download & unpack Task A data
â”‚   â”œâ”€â”€ gender_classification_convnext.ipynb  # notebook (exploration)
â”‚   â”œâ”€â”€ train.py                         # training script
â”‚   â”œâ”€â”€ test.py                          # inference & submission script
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ comsys-hackathon-taskB/
â”‚   â”œâ”€â”€ test_data/                       # hold-out test images
â”‚   â”œâ”€â”€ weights/
â”‚   â”‚   â””â”€â”€ best_siamese_convnext.pt
â”‚   â”œâ”€â”€ download_data.py                 # download & unpack Task B data
â”‚   â”œâ”€â”€ face_recognition_siamese.ipynb   # notebook (exploration)
â”‚   â”œâ”€â”€ train.py                         # training script
â”‚   â”œâ”€â”€ test.py                          # inference script
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ README.md                            # technical overview
```

---

# ğŸ§  Task A: Gender Classification

This repository implements a **ConvNeXtâ€‘Atto**â€‘based classifier to predict gender (male/female) from face images. Class imbalance is handled via random undersampling of the majority (male) class and focal loss with label smoothing.

---

## ğŸ“‚ Dataset Layout (after download)

```
Comys_Hackathon5/
â””â”€â”€ Task_A/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ male/
    â”‚   â”‚   â”œâ”€â”€ img_001.jpg
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ female/
    â”‚       â”œâ”€â”€ img_777.jpg
    â”‚       â””â”€â”€ ...
    â””â”€â”€ val/
        â”œâ”€â”€ male/
        â””â”€â”€ female/
```

---

## ğŸ§¹ Data Preâ€‘processing

| Step                     | Purpose                                                                                              |
| ------------------------ | ---------------------------------------------------------------------------------------------------- |
| **Random undersampling** | Reduce 1623 male images down to 303 to match female count; mitigates class bias.                     |
| **Augmentations**        | Resize â†’ 224Ã—224, `HorizontalFlip`, `ColorJitter`, `RandomRotation(Â±15Â°)` to improve generalisation. |

All transforms implemented with **torchvision**.

---

## ğŸ—ï¸ Model Architecture

```
ConvNeXtâ€‘Atto (preâ€‘trained, features only)
       â†“
Linear(num_features â†’ 1)
```

* **Backbone**: ConvNeXtâ€‘Atto from [`timm`](https://github.com/huggingface/pytorch-image-models) with frozen weights.
* **Head**: Single linear layer â” sigmoid via `BCEWithLogits`.

---

## ğŸ“‰ Loss Function

### Focal LossÂ + Label Smoothing

```
FL = Î± Â· (1 âˆ’ p_t)^Î³ Â· CE_smooth
```

* Smoothing Îµ = 0.1
* Î³ = 2, Î± = 1

Provides extra focus on hard / minority samples.

---

## ğŸš€ Training Configuration

| Setting         | Value                    |
| --------------- | ------------------------ |
| Optimizer       | AdamW                    |
| Base LR         | 1eâ€‘4                     |
| Scheduler       | CosineAnnealingLR (T=10) |
| Epochs          | 50                       |
| Batch Size      | 32                       |
| Mixed Precision | âœ… (`torch.cuda.amp`)     |
| Model Selection | Highest validation acc   |

---

## âœ… Results

| Metric                       | Value       |
| ---------------------------- | ----------- |
| **Best Validation Accuracy** | **96.37â€¯%** |

The best checkpoint is saved to `weights/best_convnext_gender_model.pth` and loaded automatically by `test.py`.

---

## ğŸ› ï¸ Requirements

```bash
pip install -r requirements.txt
```

* **Key Libraries:** PyTorchÂ â‰¥Â 2.0, `timm`, `torchvision`, `Pillow`

---

## ğŸ”„ Training & Evaluation

```bash
# Train
python train.py --data_dir /path/to/Comys_Hackathon5/Task_A --epochs 50

# Inference on organiser test set
python test.py  --weights weights/best_convnext_gender_model.pth \
                --img_dir  test_data/ \
                --output   submission.csv
```

---

## âœï¸ Notes

* Class imbalance is tackled via **undersampling + focal loss** rather than oversampling to keep training stable.
* ConvNeXtâ€‘Atto offers an excellent speed/accuracy tradeâ€‘off, ideal for limited GPU quotas.
* Further gains could come from classâ€‘balanced loss or larger ConvNeXt variants if compute allows.

---

# ğŸ§  Task B: Face Recognition (Siamese Network)

This repository implements a Siamese Neural Network using a ConvNeXt-Atto encoder for face verification under distortion. The network learns to embed similar faces closer together while pushing dissimilar pairs apart using Contrastive Loss.

---

## âš™ï¸ Setup Instructions

Follow these steps to set up your environment and run the project:

```bash
# Step 1: Clone the repository
git clone https://github.com/EnvyThunder/Comsys_25
cd comsys-hackathon-taskB

# Step 2: Create a virtual environment
python3 -m venv venv

# Step 3: Activate the virtual environment
source venv/bin/activate  # On Windows use: venv\Scripts\activate

# Step 4: Install all dependencies
pip install -r requirements.txt

# Step 5: Download dataset (Google Drive link embedded in script)
python3 download_data.py  # Downloads and sets up dataset locally

# Step 6: Run training (adjust path if needed)
python3 train.py --data_dir /path/to/Comys_Hackathon5/Task_B --epochs 50

# Step 7: Place test dataset inside the `test_data/` directory

# Step 8: Run inference
python3 test.py --weights weights/best_siamese_convnext.pt                 --img_dir  test_data/                 --output   submission.csv
```

---

## ğŸ“‚ Dataset Structure

```
Comys_Hackathon5/
â””â”€â”€ Task_B/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ person_1/
    â”‚   â”‚   â”œâ”€â”€ image1.jpg
    â”‚   â”‚   â”œâ”€â”€ image2.jpg
    â”‚   â”‚   â””â”€â”€ distortion/        # flattened automatically
    â”‚   â””â”€â”€ ...
    â””â”€â”€ val/
        â”œâ”€â”€ person_2/
        â”‚   â”œâ”€â”€ image1.jpg
        â”‚   â””â”€â”€ distortion/
        â””â”€â”€ ...
```

Each class folder may contain a `distortion/` subfolder with additional samples. This is flattened at runtime.

---

## ğŸ“¦ Components

### ğŸ§¹ Data Preprocessing

- **Distortion Flattening:** Moves images from `distortion/` subfolders into their parent identity class folders.
- **Pair Generation:**
  - Positive Pairs: Two images from the same identity.
  - Negative Pairs: One image from the current identity and one from a different random identity.

### ğŸ–¼ï¸ Data Augmentation

Implemented using **Albumentations**:

- **Training Transforms:**
  - Resize(224, 224)
  - HorizontalFlip, BrightnessContrast, HueSaturation, ShiftScaleRotate
  - Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))
  - ToTensorV2

- **Validation Transforms:**
  - Resize(224, 224)
  - Normalize
  - ToTensorV2

---

## ğŸ—ï¸ Model Architecture

```
ConvNeXt-Atto (pretrained, no classifier head)
        â†“
    Linear â†’ ReLU â†’ Linear â†’ L2 Normalization
```

- **Backbone:** ConvNeXt-Atto from `timm`
- **Projection Head:**  
  - Linear(encoder_out â†’ 512) â†’ ReLU â†’ Linear(512 â†’ 128)
- **Output:** Normalized embeddings using L2 norm
- **Shared encoder** is used for both image branches

---

## ğŸ“‰ Loss Function

**Contrastive Loss**

Minimizes distance for similar pairs, maximizes for dissimilar pairs.

```
Loss = y * d^2 + (1 - y) * max(0, margin - d)^2
```

Where:
- `y âˆˆ {0, 1}` is the label
- `d` is the Euclidean distance between the embeddings
- `margin` is a hyperparameter (default = 1.0)

---

## âœ… Evaluation Metrics

- Accuracy  
- Precision  
- Recall  
- F1-Score  

**Threshold-based decision:** If distance < 0.5 â” positive match.

---

## ğŸš€ Training Configuration

| Setting           | Value               |
|-------------------|---------------------|
| Model Backbone     | ConvNeXt-Atto       |
| Loss Function      | Contrastive Loss    |
| Optimizer          | AdamW               |
| Learning Rate      | 1e-4                |
| Weight Decay       | 1e-5                |
| LR Scheduler       | CosineAnnealingLR   |
| Epochs             | 50                  |
| Batch Size         | 32                  |
| Mixed Precision    | âœ… (torch.cuda.amp) |
| Model Saving       | Based on Val Accuracy |

---

## âœ… Results

| Metric              | Value     |
|---------------------|-----------|
| Best Val Accuracy   | 97.73â€¯%   |

Best checkpoint saved to:

```
weights/best_siamese_convnext.pt
```

---

## ğŸ› ï¸ Requirements

```bash
pip install -r requirements.txt
```

---

## ğŸ”„ Training & Inference

```bash
# Train
python train.py --data_dir /path/to/Comys_Hackathon5/Task_B --epochs 50

# Inference on test pairs
python test.py --weights weights/best_siamese_convnext.pt                --img_dir  test_data/                --output   submission.csv
```

